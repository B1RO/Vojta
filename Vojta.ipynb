{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk-K2sAk193U"
      },
      "source": [
        "# Vojta\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gFgUyx-2E1k",
        "outputId": "3b7d3cc2-b95e-4145-9063-f1e5f2dbefa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.2.0 which is incompatible.\n",
            "inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m2023-05-30 17:43:47.771838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl#egg=de_core_news_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.7.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "2023-05-30 17:43:58.455129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl#egg=en_core_web_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.5.0\n",
            "    Uninstalling en-core-web-sm-3.5.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.5.0\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install portalocker\n",
        "!pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil\n",
        "!python -m spacy download de_core_news_sm \n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz-Jf_BN193W"
      },
      "source": [
        "## The dataset\n",
        "\n",
        " We wish to train our classifier on the compounds dataset available on PubCHEM. In PubCHEM terminology, a compound is a record summarizing at least one physical sample that can be obtained, analyzed, or used in experiment. Each compound record has differing amount of information, and only a subset contains both the SMILES and IUPAC names. Such compounds make up our dataset.\n",
        " To prepare the dataset we access the whole database through FTP. This is preferrable to programatic approach that is rate limited. The downloaded database consists of approximatelly 168 million records, totalling approximatelly 270 gigabytes of compressed data. These data are available in chunks of XML files, containing 500 000 records each. A size of one file is typically around 20 gigabytes.  Due to the size of the data, we iterate over each XML file in a stream-like manner, and try to extract the id, SMILES, IUPAC name. Those compounds that contain all three are\n",
        " saved into a tsv file. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZyoRNr0193W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('concatenated_data.tsv', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU6OioAv193Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, random_split\n",
        "\n",
        "\n",
        "# Custom dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.data[\" SMILES\"][idx], self.data[\" IUPAC\"][idx])\n",
        "\n",
        "\n",
        "\n",
        "# Create a custom dataset\n",
        "dataset = MyDataset(df)\n",
        "\n",
        "# Define the sizes for train, validation, and test datasets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Split the dataset into train, validation, and test datasets\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2G2KV0mGTXJO",
        "outputId": "12306ad0-8500-4490-9849-6b8824275bd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ee264c3-3a60-4aad-a192-e078b8139d9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CID</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>IUPAC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CC(=O)OC(CC(=O)[O-])C[N+](C)(C)C</td>\n",
              "      <td>3-acetoxy-4-(trimethylammonio)butanoate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>CC(=O)OC(CC(=O)O)C[N+](C)(C)C</td>\n",
              "      <td>(2-acetoxy-3-carboxy-propyl)-trimethyl-ammonium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C1=CC(C(C(=C1)C(=O)O)O)O</td>\n",
              "      <td>5,6-dihydroxycyclohexa-1,3-diene-1-carboxylic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>C(CCl)Cl</td>\n",
              "      <td>1,2-dichloroethane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>C(C(C(C(=O)C(=O)C(=O)O)O)O)O</td>\n",
              "      <td>4,5,6-trihydroxy-2,3-dioxo-hexanoic acid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376447</th>\n",
              "      <td>55226682</td>\n",
              "      <td>[B-](CN1C=CC=NC1=O)(F)(F)F</td>\n",
              "      <td>trifluoro-[(2-oxopyrimidin-1-yl)methyl]boranuide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376448</th>\n",
              "      <td>55226712</td>\n",
              "      <td>C1=CC(=C(C=C1SC2=NC=NC=C2)Cl)C(=O)O</td>\n",
              "      <td>2-chloro-4-pyrimidin-4-ylsulfanyl-benzoic acid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376449</th>\n",
              "      <td>55226859</td>\n",
              "      <td>C1=CC(=C(C=C1F)CNS(=O)(=O)C2=C(C=CS2)Br)F</td>\n",
              "      <td>3-bromo-N-[(2,5-difluorophenyl)methyl]thiophen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376450</th>\n",
              "      <td>55226893</td>\n",
              "      <td>CC1=CC(=NC=N1)N2CCC(C2)(C(=O)O)C(F)(F)F</td>\n",
              "      <td>1-(6-methylpyrimidin-4-yl)-3-(trifluoromethyl)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376451</th>\n",
              "      <td>55227049</td>\n",
              "      <td>C1=CC(=C(C=C1NC2=CC(=C(C=C2)F)Cl)Cl)C#N</td>\n",
              "      <td>2-chloro-4-(3-chloro-4-fluoro-anilino)benzonit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>376452 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee264c3-3a60-4aad-a192-e078b8139d9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ee264c3-3a60-4aad-a192-e078b8139d9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ee264c3-3a60-4aad-a192-e078b8139d9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             CID                                     SMILES  \\\n",
              "0              1           CC(=O)OC(CC(=O)[O-])C[N+](C)(C)C   \n",
              "1              2              CC(=O)OC(CC(=O)O)C[N+](C)(C)C   \n",
              "2              3                   C1=CC(C(C(=C1)C(=O)O)O)O   \n",
              "3             11                                   C(CCl)Cl   \n",
              "4             18               C(C(C(C(=O)C(=O)C(=O)O)O)O)O   \n",
              "...          ...                                        ...   \n",
              "376447  55226682                 [B-](CN1C=CC=NC1=O)(F)(F)F   \n",
              "376448  55226712        C1=CC(=C(C=C1SC2=NC=NC=C2)Cl)C(=O)O   \n",
              "376449  55226859  C1=CC(=C(C=C1F)CNS(=O)(=O)C2=C(C=CS2)Br)F   \n",
              "376450  55226893    CC1=CC(=NC=N1)N2CCC(C2)(C(=O)O)C(F)(F)F   \n",
              "376451  55227049    C1=CC(=C(C=C1NC2=CC(=C(C=C2)F)Cl)Cl)C#N   \n",
              "\n",
              "                                                    IUPAC  \n",
              "0                 3-acetoxy-4-(trimethylammonio)butanoate  \n",
              "1         (2-acetoxy-3-carboxy-propyl)-trimethyl-ammonium  \n",
              "2       5,6-dihydroxycyclohexa-1,3-diene-1-carboxylic ...  \n",
              "3                                      1,2-dichloroethane  \n",
              "4                4,5,6-trihydroxy-2,3-dioxo-hexanoic acid  \n",
              "...                                                   ...  \n",
              "376447   trifluoro-[(2-oxopyrimidin-1-yl)methyl]boranuide  \n",
              "376448     2-chloro-4-pyrimidin-4-ylsulfanyl-benzoic acid  \n",
              "376449  3-bromo-N-[(2,5-difluorophenyl)methyl]thiophen...  \n",
              "376450  1-(6-methylpyrimidin-4-yl)-3-(trifluoromethyl)...  \n",
              "376451  2-chloro-4-(3-chloro-4-fluoro-anilino)benzonit...  \n",
              "\n",
              "[376452 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKtVjpoq193Y"
      },
      "source": [
        "## Tokenization & Vocabulary "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiX9TUuj193Y",
        "outputId": "15e114b8-8f5c-4a74-bf86-1de3618982d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import spacy\n",
        "\n",
        "def char_iterator(data):\n",
        "    for text in data:\n",
        "        for char in text:\n",
        "            yield char\n",
        "\n",
        "\n",
        "vocab_source = build_vocab_from_iterator(char_iterator(df[\" SMILES\"]), specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"])\n",
        "vocab_target = build_vocab_from_iterator(char_iterator(df[\" IUPAC\"]), specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"])\n",
        "print(len(vocab_source))\n",
        "\n",
        "\n",
        "class CharacterTokenizer:\n",
        "    def __init__(self, nlp):\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return [char for char in text]\n",
        "\n",
        "# Load SpaCy with a blank model\n",
        "tokenizer = CharacterTokenizer(spacy.blank(\"en\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdlvUZ3H193Z"
      },
      "source": [
        "## Model architecture\n",
        "\n",
        "As a start we use the model described in \"Attention is all you need\", the code is mostly taken from The Annotated Transformer. \n",
        "Fundamentally this model consists of two parts, an encoder and a decoder.\n",
        "The encoder encodes the SMILES string into a latent space, and the decoder produces the IUPAC name from a vector in the latent space. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xcsBK4W193Z"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many\n",
        "    other models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        \"Take in and process masked src and target sequences.\"\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy_WiN5w193Z"
      },
      "source": [
        "Our model is auto-regressive, meaning it generates one character at a time. The generator below accepts the output of the decoder (a vector) and maps it into shape (batch_size, vocab). \n",
        "Finally logmax is applied to get probabily for each possible character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReUA8Ftx193Z"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import log_softmax\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"Define standard linear + softmax generation step.\"\n",
        "\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return log_softmax(self.proj(x), dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpZPNU8d193a"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsKB_DL3193a"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "    \n",
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "    \n",
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Follow Figure 1 (left) for connections.\"\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"Core encoder is a stack of N layers\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Pass the input (and mask) through each layer in turn.\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igfdFjxX193a"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbnhY-RW193a"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"Generic N layer decoder with masking.\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "    \n",
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"Follow Figure 1 (right) for connections.\"\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
        "        torch.uint8\n",
        "    )\n",
        "    return subsequent_mask == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfcEsfhd193a"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWYCIMD2193a"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"Implements Figure 2\"\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "        query, key, value = [\n",
        "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for lin, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        # 2) Apply attention on all the projected vectors in batch.\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask=mask, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "        # 3) \"Concat\" using a view and apply a final linear.\n",
        "        x = (\n",
        "            x.transpose(1, 2)\n",
        "            .contiguous()\n",
        "            .view(nbatches, -1, self.h * self.d_k)\n",
        "        )\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oa0udcG193b"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNh992hm193b"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
        "    \n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"Implement the PE function.\"\n",
        "\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4yuh6x193b"
      },
      "source": [
        "### Full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSlmiApy193b"
      },
      "outputs": [],
      "source": [
        "def make_model(\n",
        "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
        "):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab),\n",
        "    )\n",
        "\n",
        "    # This was important from their code.\n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc1g0iIA193b"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qiFf-VV193b"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            self.tgt_y = tgt[:, 1:]\n",
        "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
        "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
        "            tgt_mask.data\n",
        "        )\n",
        "        return tgt_mask\n",
        "    \n",
        "class TrainState:\n",
        "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
        "\n",
        "    step: int = 0  # Steps in the current epoch\n",
        "    accum_step: int = 0  # Number of gradient accumulation steps\n",
        "    samples: int = 0  # total # of examples used\n",
        "    tokens: int = 0  # total # of tokens processed\n",
        "\n",
        "\n",
        "def run_epoch(\n",
        "    data_iter,\n",
        "    model,\n",
        "    loss_compute,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    mode=\"train\",\n",
        "    accum_iter=1,\n",
        "    train_state=TrainState(),\n",
        "):\n",
        "    \"\"\"Train a single epoch\"\"\"\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    n_accum = 0\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        out = model.forward(\n",
        "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
        "        )\n",
        "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
        "        # loss_node = loss_node / accum_iter\n",
        "        if mode == \"train\" or mode == \"train+log\":\n",
        "            loss_node.backward()\n",
        "            train_state.step += 1\n",
        "            train_state.samples += batch.src.shape[0]\n",
        "            train_state.tokens += batch.ntokens\n",
        "            if i % accum_iter == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                n_accum += 1\n",
        "                train_state.accum_step += 1\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        tokens += batch.ntokens\n",
        "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "            elapsed = time.time() - start\n",
        "            print(\n",
        "                (\n",
        "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
        "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
        "                )\n",
        "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
        "            )\n",
        "            start = time.time()\n",
        "            tokens = 0\n",
        "        del loss\n",
        "        del loss_node\n",
        "    return total_loss / total_tokens, train_state\n",
        "\n",
        "def rate(step, model_size, factor, warmup):\n",
        "    \"\"\"\n",
        "    we have to default the step to 1 for LambdaLR function\n",
        "    to avoid zero raising to negative power.\n",
        "    \"\"\"\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (\n",
        "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
        "    )\n",
        "\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    \"Implement label smoothing.\"\n",
        "\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        assert x.size(1) == self.size\n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, true_dist.clone().detach())\n",
        "    \n",
        "\n",
        "def loss(x, crit):\n",
        "    d = x + 3 * 1\n",
        "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n",
        "    return crit(predict.log(), torch.LongTensor([1])).data\n",
        "\n",
        "class SimpleLossCompute:\n",
        "    \"A simple loss compute and train function.\"\n",
        "\n",
        "    def __init__(self, generator, criterion):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        sloss = (\n",
        "            self.criterion(\n",
        "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
        "            )\n",
        "            / norm\n",
        "        )\n",
        "        return sloss.data * norm, sloss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUbWnxqR193c"
      },
      "outputs": [],
      "source": [
        "class DummyOptimizer(torch.optim.Optimizer):\n",
        "    def __init__(self):\n",
        "        self.param_groups = [{\"lr\": 0}]\n",
        "        None\n",
        "\n",
        "    def step(self):\n",
        "        None\n",
        "\n",
        "    def zero_grad(self, set_to_none=False):\n",
        "        Noneo\n",
        "\n",
        "\n",
        "class DummyScheduler:\n",
        "    def step(self):\n",
        "        None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yRXEWw7193c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.nn.functional import pad\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def collate_batch(\n",
        "    batch,\n",
        "    src_pipeline,\n",
        "    tgt_pipeline,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device,\n",
        "    max_padding=128,\n",
        "    pad_id=2,\n",
        "):\n",
        "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
        "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
        "    src_list, tgt_list = [], []\n",
        "    for (_src, _tgt) in batch:\n",
        "        processed_src = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    src_vocab(src_pipeline(_src)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        processed_tgt = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        src_list.append(\n",
        "            # warning - overwrites values for negative values of padding - len\n",
        "            pad(\n",
        "                processed_src,\n",
        "                (\n",
        "                    0,\n",
        "                    max_padding - len(processed_src),\n",
        "                ),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "        tgt_list.append(\n",
        "            pad(\n",
        "                processed_tgt,\n",
        "                (0, max_padding - len(processed_tgt)),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    src = torch.stack(src_list)\n",
        "    tgt = torch.stack(tgt_list)\n",
        "    return (src, tgt)\n",
        "\n",
        "\n",
        "\n",
        "def collate_batch(\n",
        "    batch,\n",
        "    src_pipeline,\n",
        "    tgt_pipeline,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device,\n",
        "    max_padding=128,\n",
        "    pad_id=2,\n",
        "):\n",
        "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
        "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
        "    src_list, tgt_list = [], []\n",
        "    for (_src, _tgt) in batch:\n",
        "        processed_src = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    src_vocab(src_pipeline(_src)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        processed_tgt = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        src_list.append(\n",
        "            # warning - overwrites values for negative values of padding - len\n",
        "            pad(\n",
        "                processed_src,\n",
        "                (\n",
        "                    0,\n",
        "                    max_padding - len(processed_src),\n",
        "                ),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "        tgt_list.append(\n",
        "            pad(\n",
        "                processed_tgt,\n",
        "                (0, max_padding - len(processed_tgt)),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    src = torch.stack(src_list)\n",
        "    tgt = torch.stack(tgt_list)\n",
        "    return (src, tgt)\n",
        "\n",
        "def create_dataloaders(\n",
        "    device,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    batch_size=12000,\n",
        "    max_padding=128,\n",
        "    is_distributed=True,\n",
        "):\n",
        "    # def create_dataloaders(batch_size=12000):\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        return collate_batch(\n",
        "            batch,\n",
        "            tokenizer,\n",
        "            tokenizer,\n",
        "            vocab_src,\n",
        "            vocab_tgt,\n",
        "            device,\n",
        "            max_padding=max_padding,\n",
        "            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n",
        "        )\n",
        "    \n",
        "\n",
        "    train_sampler = (\n",
        "        DistributedSampler(train_dataset) if is_distributed else None\n",
        "    )\n",
        "    valid_sampler = (\n",
        "        DistributedSampler(val_dataset) if is_distributed else None\n",
        "    )\n",
        "    test_sampler = (\n",
        "        DistributedSampler(val_dataset) if is_distributed else None\n",
        "    )\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(train_sampler is None),\n",
        "        sampler=train_sampler,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    valid_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(valid_sampler is None),\n",
        "        sampler=valid_sampler,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(test_sampler is None),\n",
        "        sampler=test_sampler,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    return train_dataloader, valid_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "def train_worker(\n",
        "    gpu,\n",
        "    ngpus_per_node,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    spacy_de,\n",
        "    spacy_en,\n",
        "    config,\n",
        "    is_distributed=False,\n",
        "):\n",
        "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
        "    torch.cuda.set_device(gpu)\n",
        "\n",
        "    pad_idx = vocab_tgt[\"<blank>\"]\n",
        "    d_model = 512\n",
        "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
        "    model.cuda(gpu)\n",
        "    module = model\n",
        "    is_main_process = True\n",
        "    if is_distributed:\n",
        "        dist.init_process_group(\n",
        "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
        "        )\n",
        "        model = DDP(model, device_ids=[gpu])\n",
        "        module = model.module\n",
        "        is_main_process = gpu == 0\n",
        "\n",
        "    criterion = LabelSmoothing(\n",
        "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
        "    )\n",
        "    criterion.cuda(gpu)\n",
        "\n",
        "    train_dataloader, valid_dataloader, _ = create_dataloaders(\n",
        "        gpu,\n",
        "        vocab_src,\n",
        "        vocab_tgt,\n",
        "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
        "        max_padding=config[\"max_padding\"],\n",
        "        is_distributed=is_distributed,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
        "    )\n",
        "    lr_scheduler = LambdaLR(\n",
        "        optimizer=optimizer,\n",
        "        lr_lambda=lambda step: rate(\n",
        "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    \n",
        "   \n",
        "    if \"resume_checkpoint\" in config:\n",
        "         checkpoint_path = config[\"resume_checkpoint\"]\n",
        "         checkpoint = torch.load(checkpoint_path)\n",
        "         model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "         optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "         lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler_state_dict\"])\n",
        "         train_state = checkpoint[\"train_state\"]\n",
        "         start_epoch = checkpoint[\"epoch\"] + 1\n",
        "         print(f\"Resuming training from checkpoint: {checkpoint_path}, epoch {start_epoch}\")\n",
        "    else:\n",
        "        train_state = TrainState()\n",
        "        start_epoch = 0\n",
        "\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch+config[\"num_epochs\"]):\n",
        "        if is_distributed:\n",
        "            train_dataloader.sampler.set_epoch(epoch)\n",
        "            valid_dataloader.sampler.set_epoch(epoch)\n",
        "\n",
        "        model.train()\n",
        "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
        "        _, train_state = run_epoch(\n",
        "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
        "            model,\n",
        "            SimpleLossCompute(module.generator, criterion),\n",
        "            optimizer,\n",
        "            lr_scheduler,\n",
        "            mode=\"train+log\",\n",
        "            accum_iter=config[\"accum_iter\"],\n",
        "            train_state=train_state,\n",
        "        )\n",
        "\n",
        "        GPUtil.showUtilization()\n",
        "        if is_main_process:\n",
        "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state_dict\": module.state_dict(),\n",
        "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                    \"lr_scheduler_state_dict\": lr_scheduler.state_dict(),\n",
        "                    \"train_state\": train_state,\n",
        "                },\n",
        "                file_path,\n",
        "            )\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
        "        model.eval()\n",
        "        sloss = run_epoch(\n",
        "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
        "            model,\n",
        "            SimpleLossCompute(module.generator, criterion),\n",
        "            DummyOptimizer(),\n",
        "            DummyScheduler(),\n",
        "            mode=\"eval\",\n",
        "        )\n",
        "        print(sloss)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if is_main_process:\n",
        "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
        "        torch.save(module.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "vXwZg4OF88mf",
        "outputId": "75e2e9c3-627d-4628-c863-6953417d4e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0\n",
            "    Uninstalling torch-1.11.0:\n",
            "      Successfully uninstalled torch-1.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu113\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==1.11.0+cu113 --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EonWjyq9193c"
      },
      "outputs": [],
      "source": [
        "from os.path import exists\n",
        "import math\n",
        "import GPUtil\n",
        "\n",
        "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
        "    ngpus = torch.cuda.device_count()\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
        "    print(f\"Number of GPUs detected: {ngpus}\")\n",
        "    print(\"Spawning training processes ...\")\n",
        "    mp.spawn(\n",
        "        train_worker,\n",
        "        nprocs=ngpus,\n",
        "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
        "    if config[\"distributed\"]:\n",
        "        train_distributed_model(\n",
        "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
        "        )\n",
        "    else:\n",
        "        train_worker(\n",
        "            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n",
        "        )\n",
        "\n",
        "config = {\n",
        "        \"batch_size\": 400,\n",
        "        \"distributed\": False,\n",
        "        \"num_epochs\": 100,\n",
        "        \"accum_iter\": 10,\n",
        "        \"base_lr\": 1.0,\n",
        "        \"max_padding\": 72,\n",
        "        \"warmup\": 3000,\n",
        "        \"file_prefix\": \"multi30k_model_58.pt\",\n",
        "        # \"resume_checkpoint\" : \"multi30k_model_38.pt\"\n",
        "    }\n",
        "\n",
        "def load_trained_model(force_train=False):\n",
        "    model_path = \"multi30k_model_58.pt\"\n",
        "    if force_train or not exists(model_path):\n",
        "      train_model(vocab_source, vocab_target, tokenizer, tokenizer, config)\n",
        "\n",
        "    model = make_model(len(vocab_source), len(vocab_target), N=6)\n",
        "    checkpoint = torch.load(\"multi30k_model_58.pt\")\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "model = load_trained_model(force_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv5VtN5rM31D",
        "outputId": "135a8591-1b84-4255-f515-596871482729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA4DmKo7ZAq8"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len - 1):\n",
        "        out = model.decode(\n",
        "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
        "        )\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnJzMu6Y7Zo7"
      },
      "source": [
        "ahoj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQMaIgY7XxSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22a579cd-4b73-4106-a37b-0580e77e7c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing Data ...\n",
            "Loading Trained Model ...\n",
            "Checking Model Outputs:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 1/37646 [00:04<44:35:58,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 1 Accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 2/37646 [00:09<47:33:30,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 2 Accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 3/37646 [00:14<51:38:29,  4.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 3 Accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 4/37646 [00:18<49:11:29,  4.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>mercury(1+)</s>\n",
            "PREDICTED: <s>mercuric(1+)</s>\n",
            "Samples 4 Accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 5/37646 [00:23<47:47:58,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 5 Accuracy 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 6/37646 [00:28<49:07:59,  4.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 6 Accuracy 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 7/37646 [00:32<49:05:51,  4.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 7 Accuracy 0.8571428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 8/37646 [00:37<47:49:12,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 8 Accuracy 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 9/37646 [00:41<47:14:46,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 9 Accuracy 0.8888888888888888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 11/37646 [00:50<47:42:35,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 11 Accuracy 0.9090909090909091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 12/37646 [00:55<46:39:27,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 12 Accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 13/37646 [01:00<48:32:38,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>N-(2-methyl-2,3-dihydro-1,5-benzothiazepin-4-yl)hydroxylamine</s>\n",
            "PREDICTED: <s>N-(2-methyl-3,4-dihydro-2H-1,5-benzothiazepin-4-yl)hydroxylamine</s>\n",
            "Samples 13 Accuracy 0.8461538461538461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 14/37646 [01:04<48:10:49,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 14 Accuracy 0.8571428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 15/37646 [01:08<47:08:27,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 15 Accuracy 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 16/37646 [01:13<47:07:31,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>neptunium;oxygen(2-)</s>\n",
            "PREDICTED: <s>oxygen(2-);propane</s>\n",
            "Samples 16 Accuracy 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 17/37646 [01:18<48:37:45,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 17 Accuracy 0.8235294117647058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 18/37646 [01:22<47:38:38,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>methyl 2-(4-amino-5,6-dihydrothieno[2,3-d]pyrimidin-2-yl)acetate</s>\n",
            "PREDICTED: <s>methyl 2-(6-amino-5,7-dihydrothieno[2,3-d]pyrimidin-4-yl)acetate</s>\n",
            "Samples 18 Accuracy 0.7777777777777778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 19/37646 [01:27<46:48:41,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 19 Accuracy 0.7894736842105263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 21/37646 [01:36<48:09:23,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 21 Accuracy 0.8095238095238095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 22/37646 [01:40<47:08:41,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>4-phenylthieno[3,2-c]pyridine</s>\n",
            "PREDICTED: <s>7-phenylthieno[2,3-c]pyridine</s>\n",
            "Samples 22 Accuracy 0.7727272727272727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 23/37646 [01:45<46:46:46,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 23 Accuracy 0.782608695652174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 24/37646 [01:50<49:16:43,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 24 Accuracy 0.7916666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 25/37646 [01:54<47:45:31,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 25 Accuracy 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 26/37646 [01:58<46:55:43,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 26 Accuracy 0.8076923076923077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 27/37646 [02:04<48:51:31,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 27 Accuracy 0.8148148148148148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 28/37646 [02:08<48:02:20,  4.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 28 Accuracy 0.8214285714285714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 29/37646 [02:12<47:11:07,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 29 Accuracy 0.8275862068965517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 31/37646 [02:22<48:36:11,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 31 Accuracy 0.8387096774193549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 32/37646 [02:26<47:20:58,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 32 Accuracy 0.84375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 33/37646 [02:30<46:29:39,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 33 Accuracy 0.8484848484848485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 34/37646 [02:35<47:33:02,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 34 Accuracy 0.8529411764705882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 35/37646 [02:40<47:34:04,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>(2R)-3-amino-2-(methylamino)-3-oxo-propanedithioic acid</s>\n",
            "PREDICTED: <s>(2R)-2-(methylamino)-2-oxo-ethanedithioic acid</s>\n",
            "Samples 35 Accuracy 0.8285714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 36/37646 [02:44<46:32:27,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 36 Accuracy 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 37/37646 [02:48<46:29:49,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 37 Accuracy 0.8378378378378378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 38/37646 [02:53<48:37:17,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 38 Accuracy 0.8421052631578947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 39/37646 [02:58<47:27:19,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 39 Accuracy 0.8461538461538461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 41/37646 [03:07<49:00:07,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 41 Accuracy 0.8536585365853658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 42/37646 [03:12<47:55:27,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>5-chloro-N-[(5-iodo-2-furyl)methyl]-2-nitro-aniline</s>\n",
            "PREDICTED: <s>5-chloro-4-[(5-iodo-2-furyl)methyl]-2-nitro-aniline</s>\n",
            "Samples 42 Accuracy 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 43/37646 [03:16<46:55:39,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>6-oxa-2-azabicyclo[3.1.0]hexan-4-one</s>\n",
            "PREDICTED: <s>6-oxa-2-azabicyclo[3.1.0]hexan-3-one</s>\n",
            "Samples 43 Accuracy 0.813953488372093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 44/37646 [03:21<48:08:26,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 44 Accuracy 0.8181818181818182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 45/37646 [03:25<48:22:52,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 45 Accuracy 0.8222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 46/37646 [03:30<47:11:41,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>2-thioxo-1-[2-(trifluoromethoxy)phenyl]pyrimidin-4-one</s>\n",
            "PREDICTED: <s>1-[2-(trifluoromethoxy)phenyl]-2-thioxo-pyrimidin-4-one</s>\n",
            "Samples 46 Accuracy 0.8043478260869565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 47/37646 [03:34<46:46:36,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 47 Accuracy 0.8085106382978723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 48/37646 [03:39<48:16:40,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 48 Accuracy 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 49/37646 [03:43<47:18:28,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 49 Accuracy 0.8163265306122449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 50/37646 [03:48<46:26:45,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>6,9-dihydrodibenzofuran-3-amine</s>\n",
            "PREDICTED: <s>4,9-dihydrodibenzofuran-2-amine</s>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 51/37646 [03:53<48:13:50,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 51 Accuracy 0.803921568627451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 52/37646 [03:57<48:25:22,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 52 Accuracy 0.8076923076923077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 53/37646 [04:02<49:11:27,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>1-(dideuteriomethyl)-3-methoxy-2-nitro-benzene</s>\n",
            "PREDICTED: <s>1-deuterio-3-[deuterio(nitro)methyl]-2-methoxy-benzene</s>\n",
            "Samples 53 Accuracy 0.7924528301886793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 54/37646 [04:07<50:34:35,  4.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 54 Accuracy 0.7962962962962963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 55/37646 [04:12<49:47:09,  4.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>(2S,3R,4S)-2-[(1S)-1,2-dihydroxyethyl]pyrrolidine-3,4-diol</s>\n",
            "PREDICTED: <s>(2R,3S,4S)-2-[(1R)-1,2-dihydroxyethyl]pyrrolidine-3,4-diol</s>\n",
            "Samples 55 Accuracy 0.7818181818181819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 56/37646 [04:16<48:05:06,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>3-isopropyl-4,5-dimethyl-aniline</s>\n",
            "PREDICTED: <s>4-isopropyl-2,3-dimethyl-aniline</s>\n",
            "Samples 56 Accuracy 0.7678571428571429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 57/37646 [04:21<47:54:16,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>(2R,3S,4S)-3,4-dihydroxy-2-methyl-pyrrolidine-2-carboxylic acid</s>\n",
            "PREDICTED: <s>(2R,3S,4R)-3,4-dihydroxy-2-methyl-pyrrolidine-2-carboxylic acid</s>\n",
            "Samples 57 Accuracy 0.7543859649122807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 58/37646 [04:26<49:38:43,  4.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 58 Accuracy 0.7586206896551724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 59/37646 [04:30<48:05:30,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>2-cyano-N-methyl-N-(2-methylbutyl)acetamide</s>\n",
            "PREDICTED: <s>2-cyano-N-(2-methylbutyl)-N-methyl-acetamide</s>\n",
            "Samples 59 Accuracy 0.7457627118644068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 61/37646 [04:39<48:06:35,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 61 Accuracy 0.7540983606557377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 62/37646 [04:44<47:52:45,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>N,2-dimethylbutanediamide</s>\n",
            "PREDICTED: <s>N',2-dimethylbutanediamide</s>\n",
            "Samples 62 Accuracy 0.7419354838709677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 63/37646 [04:48<46:44:39,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 63 Accuracy 0.746031746031746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 64/37646 [04:52<46:54:23,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>[2-(1,3-dithiol-2-ylidene)-1-methyl-ethyl]sulfonyl butanoate</s>\n",
            "PREDICTED: <s>1,2-bis(1,3-dithiol-2-ylidene)ethyl butanoate</s>\n",
            "Samples 64 Accuracy 0.734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 65/37646 [04:57<48:20:55,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 65 Accuracy 0.7384615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 66/37646 [05:02<47:12:59,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>3-amino-N-tert-butoxy-N,2,2-trimethyl-propanamide</s>\n",
            "PREDICTED: <s>3-amino-N-tert-butoxy-N-methyl-2-methyl-propanamide</s>\n",
            "Samples 66 Accuracy 0.7272727272727273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 67/37646 [05:06<46:24:25,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 67 Accuracy 0.7313432835820896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 68/37646 [05:11<47:50:17,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 68 Accuracy 0.7352941176470589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 69/37646 [05:15<47:22:20,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 69 Accuracy 0.7391304347826086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 71/37646 [05:25<48:20:18,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 71 Accuracy 0.7464788732394366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 72/37646 [05:29<48:26:41,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>(1R,4S)-5,6-dimethyl-2-azabicyclo[2.2.1]heptan-3-one</s>\n",
            "PREDICTED: <s>(1R,4R)-4,5-dimethyl-2-azabicyclo[2.2.1]heptan-2-one</s>\n",
            "Samples 72 Accuracy 0.7361111111111112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 73/37646 [05:34<47:13:18,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 73 Accuracy 0.7397260273972602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 74/37646 [05:38<46:38:58,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>4-hydroxy-2,3,4,5-tetrahydro-2-benzazepin-1-one</s>\n",
            "PREDICTED: <s>3-hydroxy-2,5,6,8-tetrahydro-3-2-benzazazepin-1-one</s>\n",
            "Samples 74 Accuracy 0.7297297297297297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 75/37646 [05:43<48:57:00,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 75 Accuracy 0.7333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 76/37646 [05:47<47:24:43,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 76 Accuracy 0.7368421052631579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 77/37646 [05:51<46:20:49,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 77 Accuracy 0.7402597402597403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 78/37646 [05:56<47:24:29,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 78 Accuracy 0.7435897435897436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 79/37646 [06:01<47:42:20,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 79 Accuracy 0.7468354430379747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 81/37646 [06:10<47:03:42,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 81 Accuracy 0.7530864197530864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 82/37646 [06:15<48:51:14,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 82 Accuracy 0.7560975609756098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 83/37646 [06:19<47:31:34,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 83 Accuracy 0.7590361445783133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 84/37646 [06:23<46:37:19,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>2-(1,3-dithian-2-ylidene)tetralin-1-one</s>\n",
            "PREDICTED: <s>2-(1,3-dithian-2-ylidene)indan-1-one</s>\n",
            "Samples 84 Accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 85/37646 [06:29<49:37:32,  4.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 85 Accuracy 0.7529411764705882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 86/37646 [06:33<48:05:31,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 86 Accuracy 0.7558139534883721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 87/37646 [06:37<46:57:22,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 87 Accuracy 0.7586206896551724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 88/37646 [06:42<47:34:56,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 88 Accuracy 0.7613636363636364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 89/37646 [06:47<47:52:15,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples 89 Accuracy 0.7640449438202247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress:   0%|          | 91/37646 [06:55<46:32:45,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TARGET: <s>3-(3,5-dinitro-1,2,4-triazol-1-yl)propanoic acid</s>\n",
            "PREDICTED: <s>3-(4,5-dinitro-1,2,4-triazol-1-yl)propanoic acid</s>\n",
            "Samples 91 Accuracy 0.7582417582417582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidation Progress:   0%|          | 91/37646 [06:58<47:58:45,  4.60s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-74f8cf30b40c>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mrun_model_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pepa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-74f8cf30b40c>\u001b[0m in \u001b[0;36mrun_model_example\u001b[0;34m(n_examples)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checking Model Outputs:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     example_data = check_outputs(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-70-74f8cf30b40c>\u001b[0m in \u001b[0;36mcheck_outputs\u001b[0;34m(valid_dataloader, model, vocab_src, vocab_tgt, pad_idx, eos_string)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             predicted = (\n\u001b[1;32m     33\u001b[0m                 \"\".join(\n",
            "\u001b[0;32m<ipython-input-34-9952892329d5>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         out = model.decode(\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-6-116f36b744dd>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-dc07933cc915>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-dc07933cc915>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c1615a45cacf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sublayer)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"Apply residual connection to any sublayer with the same size.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4098c06bc160>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def check_outputs(\n",
        "    valid_dataloader,\n",
        "    model,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    pad_idx=2,\n",
        "    eos_string=\"</s>\",\n",
        "):\n",
        "    correct = 0\n",
        "    total_examples = len(valid_dataloader)\n",
        "    i = 0\n",
        "\n",
        "    with tqdm(total=total_examples, desc='Validation Progress') as pbar:\n",
        "        for b in valid_dataloader:\n",
        "            if i % 10:\n",
        "              print(\"Samples\", str(i), \"Accuracy\", correct/i)\n",
        "            rb = Batch(b[0], b[1], pad_idx)\n",
        "\n",
        "            greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
        "\n",
        "            src_tokens = [\n",
        "                vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
        "            ]\n",
        "            tgt_tokens = [\n",
        "                vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
        "            ]\n",
        "            target = \"\".join(tgt_tokens).replace(\"\\n\", \"\")\n",
        "\n",
        "            model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
        "            predicted = (\n",
        "                \"\".join(\n",
        "                    [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
        "                ).split(eos_string, 1)[0]\n",
        "                + eos_string\n",
        "            ).replace(\"\\n\", \"\")\n",
        "\n",
        "            correct += predicted == target\n",
        "            pbar.update(1)\n",
        "            if predicted!=target:\n",
        "              print(\"\\nTARGET:\", target)\n",
        "              print(\"PREDICTED:\", predicted)\n",
        "            i+=1\n",
        "\n",
        "    return correct / total_examples\n",
        "\n",
        "def run_model_example(n_examples=5):\n",
        "    global vocab_source, vocab_target\n",
        "\n",
        "    print(\"Preparing Data ...\")\n",
        "    _, _, valid_dataloader = create_dataloaders(\n",
        "        torch.device(\"cpu\"),\n",
        "        vocab_source,\n",
        "        vocab_target,\n",
        "        batch_size=1,\n",
        "        is_distributed=False,\n",
        "    )\n",
        "\n",
        "    print(\"Loading Trained Model ...\")\n",
        "\n",
        "    model = make_model(len(vocab_source), len(vocab_target), N=6)\n",
        "    checkpoint = torch.load(\"multi30k_model_58.pt\", map_location=torch.device(\"cpu\"))\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    print(\"Checking Model Outputs:\")\n",
        "    example_data = check_outputs(\n",
        "        valid_dataloader, model, vocab_source, vocab_target,\n",
        "    )\n",
        "    return model, example_data\n",
        "\n",
        "\n",
        "run_model_example()\n",
        "print(\"Pepa\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ePt6gLnEixZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}